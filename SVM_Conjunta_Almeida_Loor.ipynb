{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Despliegue de Modelo - Evaluación Conjunta"
      ],
      "metadata": {
        "id": "oeCrBKeIKYG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero que haremos, será el ver que es lo que contiene nuestro dataset"
      ],
      "metadata": {
        "id": "UwK25ubvKaZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W1zAcwBkKVZ0"
      },
      "outputs": [],
      "source": [
        "# Importamos nuestras librerías\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def leer_datos(ruta):\n",
        "    df = pd.read_csv(ruta,sep=',')\n",
        "    return df"
      ],
      "metadata": {
        "id": "Vod8hwRmKddt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entrenamiento = leer_datos(\"data_evaluacion.csv\")\n",
        "entrenamiento.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEgiKyPqKe6u",
        "outputId": "915f7e87-adc3-467d-b151-7c7b0f66a634"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48841 entries, 0 to 48840\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   39             48841 non-null  int64 \n",
            " 1   State-gov      48841 non-null  object\n",
            " 2   77516          48841 non-null  int64 \n",
            " 3   Bachelors      48841 non-null  object\n",
            " 4   13             48841 non-null  int64 \n",
            " 5   Never-married  48841 non-null  object\n",
            " 6   Adm-clerical   48841 non-null  object\n",
            " 7   Not-in-family  48841 non-null  object\n",
            " 8   White          48841 non-null  object\n",
            " 9   Male           48841 non-null  object\n",
            " 10  2174           48841 non-null  int64 \n",
            " 11  0              48841 non-null  int64 \n",
            " 12  40             48841 non-null  int64 \n",
            " 13  United-States  48841 non-null  object\n",
            " 14  <=50K          48841 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vemos, nuestro dataset consta de 48841 datos, sin embargo, colocaremos encabezados basados en la información de nuestro dataset, para que nos sea más fácil entender las columnas que estamos manejando."
      ],
      "metadata": {
        "id": "w23fPbkKKgrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el archivo CSV de la evaluacion\n",
        "file_path = 'data_evaluacion.csv'\n",
        "df = pd.read_csv(file_path, header=None)  # header=None indica que el archivo CSV no tiene encabezado\n",
        "\n",
        "# Asignamos títulos a las columnas\n",
        "df.columns = ['Edad', 'ClaseObrera', 'PesoFinal', 'Educacion', 'EducacionNum', 'EstadoMarital', 'Ocupacion', 'EstadoCivil', 'Raza', 'Sexo', 'GananciaCapital'\n",
        ", 'PerdidaCapital', 'HorasPorSemana', 'Pais', 'Salario']\n",
        "\n",
        "# Guardamos el DataFrame con los nuevos títulos de columna\n",
        "df.to_csv('data_evaluacion_encabezados.csv', index=False)\n",
        "\n",
        "print(\"Archivo CSV con encabezados guardado con éxito.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsrRBll4KhPp",
        "outputId": "682ef8c9-2a78-4008-df7f-6b783c0c106b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo CSV con encabezados guardado con éxito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Volvemos a ver si nuestro nuevo archivo tiene los mismos datos\n",
        "\n",
        "df = leer_datos(\"data_evaluacion_encabezados.csv\")\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM5eegIQKism",
        "outputId": "41c515ce-8966-4355-f573-0ec31cacccfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Edad             48842 non-null  int64 \n",
            " 1   ClaseObrera      48842 non-null  object\n",
            " 2   PesoFinal        48842 non-null  int64 \n",
            " 3   Educacion        48842 non-null  object\n",
            " 4   EducacionNum     48842 non-null  int64 \n",
            " 5   EstadoMarital    48842 non-null  object\n",
            " 6   Ocupacion        48842 non-null  object\n",
            " 7   EstadoCivil      48842 non-null  object\n",
            " 8   Raza             48842 non-null  object\n",
            " 9   Sexo             48842 non-null  object\n",
            " 10  GananciaCapital  48842 non-null  int64 \n",
            " 11  PerdidaCapital   48842 non-null  int64 \n",
            " 12  HorasPorSemana   48842 non-null  int64 \n",
            " 13  Pais             48842 non-null  object\n",
            " 14  Salario          48842 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos si hay valores nulos en las columnas\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKaeFG5lKlMf",
        "outputId": "d7166804-4dd2-4a63-f350-83394ac98460"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edad               0\n",
            "ClaseObrera        0\n",
            "PesoFinal          0\n",
            "Educacion          0\n",
            "EducacionNum       0\n",
            "EstadoMarital      0\n",
            "Ocupacion          0\n",
            "EstadoCivil        0\n",
            "Raza               0\n",
            "Sexo               0\n",
            "GananciaCapital    0\n",
            "PerdidaCapital     0\n",
            "HorasPorSemana     0\n",
            "Pais               0\n",
            "Salario            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de Datos"
      ],
      "metadata": {
        "id": "vxVKAhntKnC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos variables categóricas a numéricas\n",
        "le = LabelEncoder()\n",
        "categorical_columns = ['ClaseObrera', 'Educacion', 'EstadoMarital', 'Ocupacion', 'EstadoCivil', 'Raza', 'Sexo', 'Pais', 'Salario']\n",
        "for col in categorical_columns:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Separamos características y variable objetivo\n",
        "X = df.drop('Salario', axis=1)\n",
        "y = df['Salario']\n",
        "\n",
        "# Dividimos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalamos las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "31ffezYdKo4-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMALIZACION DE CARACTERISTICAS NUMERICAS\n",
        "scaler = StandardScaler()\n",
        "numeric_columns = X.select_dtypes(include=[np.number]).columns\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
        "X_test_scaled[numeric_columns] = scaler.transform(X_test[numeric_columns])\n"
      ],
      "metadata": {
        "id": "aExMqnAtKsa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de SVM\n"
      ],
      "metadata": {
        "id": "xHpNDiDTKvM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para entrenar y evaluar modelos\n",
        "def train_evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} - Accuracy: {accuracy}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return model, accuracy\n",
        "\n",
        "# SVM (4 kernels)\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "svm_models = {}\n",
        "for kernel in kernels:\n",
        "    svm_model, svm_accuracy = train_evaluate_model(SVC(kernel=kernel, random_state=42), X_train_scaled, X_test_scaled, y_train, y_test, f\"SVM ({kernel})\")\n",
        "    svm_models[kernel] = (svm_model, svm_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxwLXEaIKw_-",
        "outputId": "a7bda1cb-4687-4b0e-d6ae-3fe7a14bb4af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (linear) - Accuracy: 0.8127751049237384\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.98      0.89      7414\n",
            "           1       0.79      0.30      0.44      2355\n",
            "\n",
            "    accuracy                           0.81      9769\n",
            "   macro avg       0.80      0.64      0.66      9769\n",
            "weighted avg       0.81      0.81      0.78      9769\n",
            "\n",
            "SVM (poly) - Accuracy: 0.8416419285494933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      7414\n",
            "           1       0.75      0.51      0.61      2355\n",
            "\n",
            "    accuracy                           0.84      9769\n",
            "   macro avg       0.81      0.73      0.75      9769\n",
            "weighted avg       0.83      0.84      0.83      9769\n",
            "\n",
            "SVM (rbf) - Accuracy: 0.8456341488381616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      7414\n",
            "           1       0.76      0.53      0.62      2355\n",
            "\n",
            "    accuracy                           0.85      9769\n",
            "   macro avg       0.81      0.74      0.76      9769\n",
            "weighted avg       0.84      0.85      0.84      9769\n",
            "\n",
            "SVM (sigmoid) - Accuracy: 0.7548367284266557\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84      7414\n",
            "           1       0.49      0.48      0.49      2355\n",
            "\n",
            "    accuracy                           0.75      9769\n",
            "   macro avg       0.66      0.66      0.66      9769\n",
            "weighted avg       0.75      0.75      0.75      9769\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificamos Overfiting o Underfiting\n",
        "def check_fit(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  Train Accuracy: {train_accuracy}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy}\")\n",
        "    if train_accuracy > test_accuracy + 0.05:\n",
        "        print(\"  Posible overfitting\")\n",
        "    elif test_accuracy > train_accuracy + 0.05:\n",
        "        print(\"  Posible underfitting\")\n",
        "    else:\n",
        "        print(\"  Buen ajuste\")\n",
        "\n",
        "# Verificar ajuste para cada modelo\n",
        "for kernel, (model, _) in svm_models.items():\n",
        "    check_fit(model, X_train_scaled, X_test_scaled, y_train, y_test, f\"SVM ({kernel})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYLYoq-TK5iT",
        "outputId": "c9a2282d-259b-4717-a52d-9621d9e9d9f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (linear):\n",
            "  Train Accuracy: 0.8136564891357203\n",
            "  Test Accuracy: 0.8127751049237384\n",
            "  Buen ajuste\n",
            "SVM (poly):\n",
            "  Train Accuracy: 0.8487702505566503\n",
            "  Test Accuracy: 0.8416419285494933\n",
            "  Buen ajuste\n",
            "SVM (rbf):\n",
            "  Train Accuracy: 0.8566273385713921\n",
            "  Test Accuracy: 0.8456341488381616\n",
            "  Buen ajuste\n",
            "SVM (sigmoid):\n",
            "  Train Accuracy: 0.7505438538120953\n",
            "  Test Accuracy: 0.7548367284266557\n",
            "  Buen ajuste\n"
          ]
        }
      ]
    }
  ]
}