{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Despliegue de Modelo - Evaluación Conjunta"
      ],
      "metadata": {
        "id": "2T2gsAEXUD-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero que haremos, será el ver que es lo que contiene nuestro dataset"
      ],
      "metadata": {
        "id": "rjX7KiLaUJxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos nuestras librerías\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "PfsQeW2hUY98"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "77zj35wQShZs"
      },
      "outputs": [],
      "source": [
        "def leer_datos(ruta):\n",
        "    df = pd.read_csv(ruta,sep=',')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entrenamiento = leer_datos(\"data_evaluacion.csv\")\n",
        "entrenamiento.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5TZDQV6UU1Z",
        "outputId": "58bfe83b-6c8b-441c-a81d-8c51d1b23385"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48841 entries, 0 to 48840\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   39             48841 non-null  int64 \n",
            " 1   State-gov      48841 non-null  object\n",
            " 2   77516          48841 non-null  int64 \n",
            " 3   Bachelors      48841 non-null  object\n",
            " 4   13             48841 non-null  int64 \n",
            " 5   Never-married  48841 non-null  object\n",
            " 6   Adm-clerical   48841 non-null  object\n",
            " 7   Not-in-family  48841 non-null  object\n",
            " 8   White          48841 non-null  object\n",
            " 9   Male           48841 non-null  object\n",
            " 10  2174           48841 non-null  int64 \n",
            " 11  0              48841 non-null  int64 \n",
            " 12  40             48841 non-null  int64 \n",
            " 13  United-States  48841 non-null  object\n",
            " 14  <=50K          48841 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vemos, nuestro dataset consta de 48841 datos, sin embargo, colocaremos encabezados basados en la información de nuestro dataset, para que nos sea más fácil entender las columnas que estamos manejando."
      ],
      "metadata": {
        "id": "qxlq2fGTUljK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el archivo CSV de la evaluacion\n",
        "file_path = 'data_evaluacion.csv'\n",
        "df = pd.read_csv(file_path, header=None)  # header=None indica que el archivo CSV no tiene encabezado\n",
        "\n",
        "# Asignamos títulos a las columnas\n",
        "df.columns = ['Edad', 'ClaseObrera', 'PesoFinal', 'Educacion', 'EducacionNum', 'EstadoMarital', 'Ocupacion', 'EstadoCivil', 'Raza', 'Sexo', 'GananciaCapital'\n",
        ", 'PerdidaCapital', 'HorasPorSemana', 'Pais', 'Salario']\n",
        "\n",
        "# Guardamos el DataFrame con los nuevos títulos de columna\n",
        "df.to_csv('data_evaluacion_encabezados.csv', index=False)\n",
        "\n",
        "print(\"Archivo CSV con encabezados guardado con éxito.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxUVkuWMUxX6",
        "outputId": "de8709ab-37fd-41c7-b448-b5bf0cd5bf76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo CSV con encabezados guardado con éxito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Volvemos a ver si nuestro nuevo archivo tiene los mismos datos\n",
        "\n",
        "df = leer_datos(\"data_evaluacion_encabezados.csv\")\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3C1j6DQU8Bs",
        "outputId": "ff6626d4-e4f1-4b30-ed8c-84d0c593a0b8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Edad             48842 non-null  int64 \n",
            " 1   ClaseObrera      48842 non-null  object\n",
            " 2   PesoFinal        48842 non-null  int64 \n",
            " 3   Educacion        48842 non-null  object\n",
            " 4   EducacionNum     48842 non-null  int64 \n",
            " 5   EstadoMarital    48842 non-null  object\n",
            " 6   Ocupacion        48842 non-null  object\n",
            " 7   EstadoCivil      48842 non-null  object\n",
            " 8   Raza             48842 non-null  object\n",
            " 9   Sexo             48842 non-null  object\n",
            " 10  GananciaCapital  48842 non-null  int64 \n",
            " 11  PerdidaCapital   48842 non-null  int64 \n",
            " 12  HorasPorSemana   48842 non-null  int64 \n",
            " 13  Pais             48842 non-null  object\n",
            " 14  Salario          48842 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos si hay valores nulos en las columnas\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kd6wcxKVSdX",
        "outputId": "b4911ef2-9a40-41ec-fc37-2cdde9670452"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edad               0\n",
            "ClaseObrera        0\n",
            "PesoFinal          0\n",
            "Educacion          0\n",
            "EducacionNum       0\n",
            "EstadoMarital      0\n",
            "Ocupacion          0\n",
            "EstadoCivil        0\n",
            "Raza               0\n",
            "Sexo               0\n",
            "GananciaCapital    0\n",
            "PerdidaCapital     0\n",
            "HorasPorSemana     0\n",
            "Pais               0\n",
            "Salario            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de Datos"
      ],
      "metadata": {
        "id": "MeEoPw3WWFpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos variables categóricas a numéricas\n",
        "le = LabelEncoder()\n",
        "categorical_columns = ['ClaseObrera', 'Educacion', 'EstadoMarital', 'Ocupacion', 'EstadoCivil', 'Raza', 'Sexo', 'Pais', 'Salario']\n",
        "for col in categorical_columns:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Separamos características y variable objetivo\n",
        "X = df.drop('Salario', axis=1)\n",
        "y = df['Salario']\n",
        "\n",
        "# Dividimos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalamos las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "RAavAUxVWFTx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMALIZACION DE CARACTERISTICAS NUMERICAS\n",
        "scaler = StandardScaler()\n",
        "numeric_columns = X.select_dtypes(include=[np.number]).columns\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
        "X_test_scaled[numeric_columns] = scaler.transform(X_test[numeric_columns])\n"
      ],
      "metadata": {
        "id": "DGXMaGF1hSAd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de los Modelos"
      ],
      "metadata": {
        "id": "tbyYm1j2Wck6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para entrenar y evaluar modelos\n",
        "def train_evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} - Accuracy: {accuracy}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return model, accuracy\n",
        "\n",
        "# Regresión Logística\n",
        "lr_model, lr_accuracy = train_evaluate_model(LogisticRegression(random_state=42), X_train_scaled, X_test_scaled, y_train, y_test, \"Logistic Regression\")\n",
        "\n",
        "# SVM (4 kernels)\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "svm_models = {}\n",
        "for kernel in kernels:\n",
        "    svm_model, svm_accuracy = train_evaluate_model(SVC(kernel=kernel, random_state=42), X_train_scaled, X_test_scaled, y_train, y_test, f\"SVM ({kernel})\")\n",
        "    svm_models[kernel] = (svm_model, svm_accuracy)\n",
        "\n",
        "# K-NN (Identificando el mejor número para k)\n",
        "k_values = range(1, 21)\n",
        "knn_accuracies = []\n",
        "for k in k_values:\n",
        "    knn_model, knn_accuracy = train_evaluate_model(KNeighborsClassifier(n_neighbors=k), X_train_scaled, X_test_scaled, y_train, y_test, f\"KNN (k={k})\")\n",
        "    knn_accuracies.append(knn_accuracy)\n",
        "\n",
        "best_k = k_values[np.argmax(knn_accuracies)]\n",
        "print(f\"Mejor valor de k: {best_k}\")\n",
        "\n",
        "# Árboles de Decisión\n",
        "dt_model, dt_accuracy = train_evaluate_model(DecisionTreeClassifier(random_state=42), X_train_scaled, X_test_scaled, y_train, y_test, \"Decision Tree\")\n",
        "\n",
        "# Naive Bayes\n",
        "nb_model, nb_accuracy = train_evaluate_model(GaussianNB(), X_train_scaled, X_test_scaled, y_train, y_test, \"Naive Bayes\")\n",
        "\n",
        "# Redes Neuronales\n",
        "nn_model, nn_accuracy = train_evaluate_model(MLPClassifier(random_state=42), X_train_scaled, X_test_scaled, y_train, y_test, \"Neural Network\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30VAdVvnWcTg",
        "outputId": "46e615f7-8c86-45d5-d8c0-74b2eb590773"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.8237281195618794\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89      7414\n",
            "           1       0.72      0.44      0.55      2355\n",
            "\n",
            "    accuracy                           0.82      9769\n",
            "   macro avg       0.78      0.69      0.72      9769\n",
            "weighted avg       0.81      0.82      0.81      9769\n",
            "\n",
            "SVM (linear) - Accuracy: 0.8127751049237384\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.98      0.89      7414\n",
            "           1       0.79      0.30      0.44      2355\n",
            "\n",
            "    accuracy                           0.81      9769\n",
            "   macro avg       0.80      0.64      0.66      9769\n",
            "weighted avg       0.81      0.81      0.78      9769\n",
            "\n",
            "SVM (poly) - Accuracy: 0.8416419285494933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      7414\n",
            "           1       0.75      0.51      0.61      2355\n",
            "\n",
            "    accuracy                           0.84      9769\n",
            "   macro avg       0.81      0.73      0.75      9769\n",
            "weighted avg       0.83      0.84      0.83      9769\n",
            "\n",
            "SVM (rbf) - Accuracy: 0.8456341488381616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      7414\n",
            "           1       0.76      0.53      0.62      2355\n",
            "\n",
            "    accuracy                           0.85      9769\n",
            "   macro avg       0.81      0.74      0.76      9769\n",
            "weighted avg       0.84      0.85      0.84      9769\n",
            "\n",
            "SVM (sigmoid) - Accuracy: 0.7548367284266557\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84      7414\n",
            "           1       0.49      0.48      0.49      2355\n",
            "\n",
            "    accuracy                           0.75      9769\n",
            "   macro avg       0.66      0.66      0.66      9769\n",
            "weighted avg       0.75      0.75      0.75      9769\n",
            "\n",
            "KNN (k=1) - Accuracy: 0.7925069096120381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      7414\n",
            "           1       0.57      0.55      0.56      2355\n",
            "\n",
            "    accuracy                           0.79      9769\n",
            "   macro avg       0.72      0.71      0.71      9769\n",
            "weighted avg       0.79      0.79      0.79      9769\n",
            "\n",
            "KNN (k=2) - Accuracy: 0.8114443648275156\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.88      7414\n",
            "           1       0.70      0.38      0.50      2355\n",
            "\n",
            "    accuracy                           0.81      9769\n",
            "   macro avg       0.76      0.67      0.69      9769\n",
            "weighted avg       0.80      0.81      0.79      9769\n",
            "\n",
            "KNN (k=3) - Accuracy: 0.8136963865288156\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      7414\n",
            "           1       0.63      0.55      0.59      2355\n",
            "\n",
            "    accuracy                           0.81      9769\n",
            "   macro avg       0.75      0.72      0.73      9769\n",
            "weighted avg       0.81      0.81      0.81      9769\n",
            "\n",
            "KNN (k=4) - Accuracy: 0.8216808271061521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89      7414\n",
            "           1       0.70      0.45      0.55      2355\n",
            "\n",
            "    accuracy                           0.82      9769\n",
            "   macro avg       0.77      0.69      0.72      9769\n",
            "weighted avg       0.81      0.82      0.81      9769\n",
            "\n",
            "KNN (k=5) - Accuracy: 0.8230115672023749\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      7414\n",
            "           1       0.66      0.56      0.60      2355\n",
            "\n",
            "    accuracy                           0.82      9769\n",
            "   macro avg       0.76      0.73      0.74      9769\n",
            "weighted avg       0.82      0.82      0.82      9769\n",
            "\n",
            "KNN (k=6) - Accuracy: 0.8249564950353158\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89      7414\n",
            "           1       0.70      0.47      0.57      2355\n",
            "\n",
            "    accuracy                           0.82      9769\n",
            "   macro avg       0.78      0.71      0.73      9769\n",
            "weighted avg       0.81      0.82      0.81      9769\n",
            "\n",
            "KNN (k=7) - Accuracy: 0.8278227044733341\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      7414\n",
            "           1       0.67      0.56      0.61      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.77      0.74      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=8) - Accuracy: 0.8304841846657796\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89      7414\n",
            "           1       0.71      0.50      0.59      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.72      0.74      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=9) - Accuracy: 0.8324291124987204\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      7414\n",
            "           1       0.69      0.56      0.62      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.74      0.76      9769\n",
            "weighted avg       0.82      0.83      0.83      9769\n",
            "\n",
            "KNN (k=10) - Accuracy: 0.8298699969290613\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89      7414\n",
            "           1       0.71      0.50      0.59      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.72      0.74      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=11) - Accuracy: 0.8333503941037977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      7414\n",
            "           1       0.69      0.56      0.62      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.74      0.76      9769\n",
            "weighted avg       0.83      0.83      0.83      9769\n",
            "\n",
            "KNN (k=12) - Accuracy: 0.8336574879721568\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.90      7414\n",
            "           1       0.71      0.52      0.60      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.79      0.73      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=13) - Accuracy: 0.8318149247620023\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      7414\n",
            "           1       0.69      0.56      0.62      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.74      0.75      9769\n",
            "weighted avg       0.82      0.83      0.83      9769\n",
            "\n",
            "KNN (k=14) - Accuracy: 0.8319172893847886\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89      7414\n",
            "           1       0.71      0.52      0.60      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.72      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=15) - Accuracy: 0.8312007370252841\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      7414\n",
            "           1       0.68      0.56      0.61      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.74      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=16) - Accuracy: 0.8316101955164296\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89      7414\n",
            "           1       0.70      0.52      0.60      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.72      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=17) - Accuracy: 0.8321220186303614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      7414\n",
            "           1       0.69      0.55      0.61      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.74      0.75      9769\n",
            "weighted avg       0.82      0.83      0.83      9769\n",
            "\n",
            "KNN (k=18) - Accuracy: 0.8325314771215068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89      7414\n",
            "           1       0.71      0.52      0.60      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.73      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "KNN (k=19) - Accuracy: 0.8320196540075749\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      7414\n",
            "           1       0.69      0.55      0.61      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.78      0.74      0.75      9769\n",
            "weighted avg       0.82      0.83      0.83      9769\n",
            "\n",
            "KNN (k=20) - Accuracy: 0.8341693110860886\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.90      7414\n",
            "           1       0.71      0.52      0.60      2355\n",
            "\n",
            "    accuracy                           0.83      9769\n",
            "   macro avg       0.79      0.73      0.75      9769\n",
            "weighted avg       0.82      0.83      0.82      9769\n",
            "\n",
            "Mejor valor de k: 20\n",
            "Decision Tree - Accuracy: 0.8107278124680111\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      7414\n",
            "           1       0.61      0.62      0.61      2355\n",
            "\n",
            "    accuracy                           0.81      9769\n",
            "   macro avg       0.74      0.74      0.74      9769\n",
            "weighted avg       0.81      0.81      0.81      9769\n",
            "\n",
            "Naive Bayes - Accuracy: 0.8028457365134609\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88      7414\n",
            "           1       0.69      0.32      0.44      2355\n",
            "\n",
            "    accuracy                           0.80      9769\n",
            "   macro avg       0.76      0.64      0.66      9769\n",
            "weighted avg       0.79      0.80      0.77      9769\n",
            "\n",
            "Neural Network - Accuracy: 0.8514689323369843\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90      7414\n",
            "           1       0.73      0.61      0.66      2355\n",
            "\n",
            "    accuracy                           0.85      9769\n",
            "   macro avg       0.81      0.77      0.78      9769\n",
            "weighted avg       0.85      0.85      0.85      9769\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recopilar accuracies\n",
        "accuracies = {\n",
        "    'Logistic Regression': lr_accuracy,\n",
        "    'SVM': max(svm_models.values(), key=lambda x: x[1])[1],\n",
        "    'KNN': max(knn_accuracies),\n",
        "    'Decision Tree': dt_accuracy,\n",
        "    'Naive Bayes': nb_accuracy,\n",
        "    'Neural Network': nn_accuracy\n",
        "}\n",
        "\n",
        "best_model = max(accuracies, key=accuracies.get)\n",
        "print(f\"El mejor modelo es: {best_model} con una precisión de {accuracies[best_model]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TteRYEBrdERU",
        "outputId": "bcac930e-37bf-4e41-d919-306d251958ba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El mejor modelo es: Neural Network con una precisión de 0.8514689323369843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificamos Overfiting o Underfiting\n",
        "def check_fit(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  Train Accuracy: {train_accuracy}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy}\")\n",
        "    if train_accuracy > test_accuracy + 0.05:\n",
        "        print(\"  Posible overfitting\")\n",
        "    elif test_accuracy > train_accuracy + 0.05:\n",
        "        print(\"  Posible underfitting\")\n",
        "    else:\n",
        "        print(\"  Buen ajuste\")\n",
        "\n",
        "# Verificar ajuste para cada modelo\n",
        "check_fit(lr_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Logistic Regression\")\n",
        "for kernel, (model, _) in svm_models.items():\n",
        "    check_fit(model, X_train_scaled, X_test_scaled, y_train, y_test, f\"SVM ({kernel})\")\n",
        "check_fit(KNeighborsClassifier(n_neighbors=best_k).fit(X_train_scaled, y_train), X_train_scaled, X_test_scaled, y_train, y_test, \"KNN\")\n",
        "check_fit(dt_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Decision Tree\")\n",
        "check_fit(nb_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Naive Bayes\")\n",
        "check_fit(nn_model, X_train_scaled, X_test_scaled, y_train, y_test, \"Neural Network\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_apIueQjnMB",
        "outputId": "388b20f9-3f14-41c4-b3e9-f881b1095c91"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "  Train Accuracy: 0.8251989865124255\n",
            "  Test Accuracy: 0.8237281195618794\n",
            "  Buen ajuste\n",
            "SVM (linear):\n",
            "  Train Accuracy: 0.8136564891357203\n",
            "  Test Accuracy: 0.8127751049237384\n",
            "  Buen ajuste\n",
            "SVM (poly):\n",
            "  Train Accuracy: 0.8487702505566503\n",
            "  Test Accuracy: 0.8416419285494933\n",
            "  Buen ajuste\n",
            "SVM (rbf):\n",
            "  Train Accuracy: 0.8566273385713921\n",
            "  Test Accuracy: 0.8456341488381616\n",
            "  Buen ajuste\n",
            "SVM (sigmoid):\n",
            "  Train Accuracy: 0.7505438538120953\n",
            "  Test Accuracy: 0.7548367284266557\n",
            "  Buen ajuste\n",
            "KNN:\n",
            "  Train Accuracy: 0.8526859980037366\n",
            "  Test Accuracy: 0.8341693110860886\n",
            "  Buen ajuste\n",
            "Decision Tree:\n",
            "  Train Accuracy: 0.9999232206382924\n",
            "  Test Accuracy: 0.8107278124680111\n",
            "  Posible overfitting\n",
            "Naive Bayes:\n",
            "  Train Accuracy: 0.8036239858725974\n",
            "  Test Accuracy: 0.8028457365134609\n",
            "  Buen ajuste\n",
            "Neural Network:\n",
            "  Train Accuracy: 0.8662247587848386\n",
            "  Test Accuracy: 0.8514689323369843\n",
            "  Buen ajuste\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Guardar el mejor modelo y el scaler\n",
        "joblib.dump(best_model, 'best_model.joblib')\n",
        "joblib.dump(scaler, 'scaler.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEBTMnQytkBP",
        "outputId": "8ae057d2-dd15-4eaa-9e2f-bfe28175e54a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el mejor modelo\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Identificar el mejor modelo\n",
        "accuracies = {\n",
        "    'Logistic Regression': lr_accuracy,\n",
        "    'SVM': max(svm_models.values(), key=lambda x: x[1])[1],\n",
        "    'KNN': max(knn_accuracies),\n",
        "    'Decision Tree': dt_accuracy,\n",
        "    'Naive Bayes': nb_accuracy,\n",
        "    'Neural Network': nn_accuracy\n",
        "}\n",
        "best_model_name = max(accuracies, key=accuracies.get)\n",
        "\n",
        "# Obtener la instancia del mejor modelo\n",
        "if best_model_name == 'Logistic Regression':\n",
        "    best_model = lr_model\n",
        "elif best_model_name.startswith('SVM'):\n",
        "    best_kernel = max(svm_models, key=lambda x: svm_models[x][1])\n",
        "    best_model = svm_models[best_kernel][0]\n",
        "elif best_model_name == 'KNN':\n",
        "    best_model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "    best_model.fit(X_train_scaled, y_train)\n",
        "elif best_model_name == 'Decision Tree':\n",
        "    best_model = dt_model\n",
        "elif best_model_name == 'Naive Bayes':\n",
        "    best_model = nb_model\n",
        "elif best_model_name == 'Neural Network':\n",
        "    best_model = nn_model\n",
        "\n",
        "# Guardar el mejor modelo\n",
        "joblib.dump(best_model, 'mejor_modelo.joblib')\n",
        "\n",
        "# Guardar el scaler\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Guardar los LabelEncoders\n",
        "encoders = {}\n",
        "for col in categorical_columns:\n",
        "    encoders[col] = LabelEncoder()\n",
        "    encoders[col].fit(df[col])\n",
        "joblib.dump(encoders, 'label_encoders.joblib')\n",
        "\n",
        "# Guardar el orden de las columnas\n",
        "joblib.dump(X.columns.tolist(), 'column_order.joblib')\n",
        "\n",
        "print(f\"El mejor modelo ({best_model_name}) ha sido guardado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSeZL7CSoCPy",
        "outputId": "8f8478f9-e374-488d-fe53-3363cbddf51e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El mejor modelo (Neural Network) ha sido guardado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de Búsqueda\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def predict_salary(data):\n",
        "    # Cargar el modelo, scaler y encoders\n",
        "    model = joblib.load('mejor_modelo.joblib')\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "    encoders = joblib.load('label_encoders.joblib')\n",
        "\n",
        "    # Definir las columnas categóricas (asegúrate de tener esta lista)\n",
        "    categorical_columns = ['ClaseObrera', 'Educacion', 'EstadoMarital', 'Ocupacion', 'EstadoCivil', 'Raza', 'Sexo', 'Pais']\n",
        "\n",
        "    # Crear una copia de los datos para no modificar el original\n",
        "    data_encoded = data.copy()\n",
        "\n",
        "    # Aplicar Label Encoding a las columnas categóricas, manejando valores desconocidos\n",
        "    for col in categorical_columns:\n",
        "        if col in data_encoded.columns:\n",
        "            if col not in encoders:\n",
        "                print(f\"Warning: No encoder found for column {col}. Skipping encoding for this column.\")\n",
        "                continue\n",
        "            encoder = encoders[col]\n",
        "            # Handle unknown values by setting them to a placeholder (e.g., 'Unknown')\n",
        "            data_encoded[col] = data_encoded[col].map(lambda s: s if s in encoder.classes_ else 'Unknown')\n",
        "            # Add 'Unknown' to the encoder classes if it's not already there\n",
        "            if 'Unknown' not in encoder.classes_:\n",
        "                encoder.classes_ = np.append(encoder.classes_, 'Unknown')\n",
        "            data_encoded[col] = encoder.transform(data_encoded[col][data_encoded[col].notna()])\n",
        "\n",
        "    # Asegurarse de que las columnas estén en el mismo orden que durante el entrenamiento\n",
        "    column_order = joblib.load('column_order.joblib')\n",
        "    missing_cols = set(column_order) - set(data_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        data_encoded[col] = 0  # o cualquier otro valor por defecto\n",
        "    data_encoded = data_encoded.reindex(columns=column_order)\n",
        "\n",
        "    # Convertir las columnas a float64 y llenar NaNs con 0\n",
        "    for col in data_encoded.columns:\n",
        "        data_encoded[col] = pd.to_numeric(data_encoded[col], errors='coerce')\n",
        "        data_encoded[col] = data_encoded[col].fillna(0)  # Reemplazar NaNs con 0\n",
        "\n",
        "    # Escalar los datos\n",
        "    X = scaler.transform(data_encoded)\n",
        "\n",
        "    # Hacer la predicción\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # Verificar si el modelo tiene el método predict_proba\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        probability = model.predict_proba(X)[:, 1]\n",
        "    else:\n",
        "        probability = None  # Para modelos que no proporcionan probabilidades\n",
        "\n",
        "    return prediction, probability\n",
        "\n",
        "# Ejemplo de uso\n",
        "new_data = pd.DataFrame({\n",
        "    'Edad': [31],\n",
        "    'ClaseObrera': ['Private'],\n",
        "    'PesoFinal': [84154],\n",
        "    'Educacion': ['Masters'],\n",
        "    'EducacionNum': [14],\n",
        "    'EstadoMarital': ['Never-married'],\n",
        "    'Ocupacion': ['Sales'],\n",
        "    'EstadoCivil': ['Husband'],\n",
        "    'Raza': ['White'],\n",
        "    'Sexo': ['Male'],\n",
        "    'GananciasCapital': [14084],\n",
        "    'PerdidasCapital': [0],\n",
        "    'HorasPorSemana': [80],\n",
        "    'Pais': ['Cuba']\n",
        "})\n",
        "\n",
        "prediction, probability = predict_salary(new_data)\n",
        "print(f\"Predicted salary: {'<=50K' if prediction[0] == 0 else '>50K'}\")\n",
        "if probability is not None:\n",
        "    print(f\"Probability of salary >50K: {probability[0]:.2f}\")\n",
        "else:\n",
        "    print(\"Probability not available for this model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECycPiJaoLWC",
        "outputId": "7e3c567b-203f-45cc-e2f5-0410bb9b6ecc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted salary: >50K\n",
            "Probability of salary >50K: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función de Predicción Mejorada\n",
        "\n",
        "Únicamente utilizada para comprobar que se está prediciendo"
      ],
      "metadata": {
        "id": "2R6s_IAhIdrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def predict_salary(data):\n",
        "    # Cargar el modelo, scaler y encoders\n",
        "    model = joblib.load('mejor_modelo.joblib')\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "    encoders = joblib.load('label_encoders.joblib')\n",
        "\n",
        "    # Definir las columnas categóricas\n",
        "    categorical_columns = ['ClaseObrera', 'Educacion', 'EstadoMarital', 'Ocupacion', 'EstadoCivil', 'Raza', 'Sexo', 'Pais']\n",
        "\n",
        "    # Crear una copia de los datos para no modificar el original\n",
        "    data_encoded = data.copy()\n",
        "\n",
        "    # Aplicar Label Encoding a las columnas categóricas, manejando valores desconocidos\n",
        "    for col in categorical_columns:\n",
        "        if col in data_encoded.columns:\n",
        "            if col not in encoders:\n",
        "                print(f\"Warning: No encoder found for column {col}. Skipping encoding for this column.\")\n",
        "                continue\n",
        "            encoder = encoders[col]\n",
        "            # Manejar valores desconocidos\n",
        "            data_encoded[col] = data_encoded[col].apply(lambda x: x if x in encoder.classes_ else 'Unknown')\n",
        "            # Asegurarse de que 'Unknown' esté en las clases del encoder\n",
        "            if 'Unknown' not in encoder.classes_:\n",
        "                encoder.classes_ = np.append(encoder.classes_, 'Unknown')\n",
        "            # Transformar los datos\n",
        "            data_encoded[col] = encoder.transform(data_encoded[col])\n",
        "\n",
        "    # Asegurarse de que las columnas estén en el mismo orden que durante el entrenamiento\n",
        "    column_order = joblib.load('column_order.joblib')\n",
        "    missing_cols = set(column_order) - set(data_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        data_encoded[col] = 0  # o cualquier otro valor por defecto\n",
        "    data_encoded = data_encoded.reindex(columns=column_order)\n",
        "\n",
        "    # Convertir las columnas a float64 y llenar NaNs con 0\n",
        "    for col in data_encoded.columns:\n",
        "        data_encoded[col] = pd.to_numeric(data_encoded[col], errors='coerce')\n",
        "        data_encoded[col] = data_encoded[col].fillna(0)  # Reemplazar NaNs con 0\n",
        "\n",
        "    # Escalar los datos\n",
        "    X = scaler.transform(data_encoded)\n",
        "\n",
        "    # Hacer la predicción\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # Verificar si el modelo tiene el método predict_proba\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        probability = model.predict_proba(X)[:, 1]\n",
        "    else:\n",
        "        probability = None  # Para modelos que no proporcionan probabilidades\n",
        "\n",
        "    return prediction, probability\n",
        "\n",
        "# Ejemplo de uso\n",
        "new_data = pd.DataFrame({\n",
        "    'Edad': [31],\n",
        "    'ClaseObrera': ['Private'],\n",
        "    'PesoFinal': [84154],\n",
        "    'Educacion': ['Masters'],\n",
        "    'EducacionNum': [14],\n",
        "    'EstadoMarital': ['Never-married'],\n",
        "    'Ocupacion': ['Sales'],\n",
        "    'EstadoCivil': ['Husband'],\n",
        "    'Raza': ['White'],\n",
        "    'Sexo': ['Male'],\n",
        "    'GananciasCapital': [14084],\n",
        "    'PerdidasCapital': [0],\n",
        "    'HorasPorSemana': [80],\n",
        "    'Pais': ['Cuba']\n",
        "})\n",
        "\n",
        "prediction, probability = predict_salary(new_data)\n",
        "print(f\"Predicted salary: {'<=50K' if prediction[0] == 0 else '>50K'}\")\n",
        "if probability is not None:\n",
        "    print(f\"Probability of salary >50K: {probability[0]:.2f}\")\n",
        "else:\n",
        "    print(\"Probability not available for this model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKvzmP52y74N",
        "outputId": "f543149f-dc47-4eee-8cc9-924a1afcc164"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted salary: >50K\n",
            "Probability of salary >50K: 0.82\n"
          ]
        }
      ]
    }
  ]
}